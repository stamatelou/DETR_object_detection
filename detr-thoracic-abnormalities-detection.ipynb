{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attractive-canon",
   "metadata": {
    "papermill": {
     "duration": 0.037329,
     "end_time": "2021-05-24T08:52:16.089335",
     "exception": false,
     "start_time": "2021-05-24T08:52:16.052006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DETR Object Detection for localization and classification of thoracic abnormalities \n",
    "Authors: Haris Mpournas & Elena Stamatelou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-radiation",
   "metadata": {
    "papermill": {
     "duration": 0.035893,
     "end_time": "2021-05-24T08:52:16.161857",
     "exception": false,
     "start_time": "2021-05-24T08:52:16.125964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Select mode\n",
    "mode='train' for the training, mode='predict' for the predictions\n",
    "uncomment the one you want to enable and comment the one you want to enable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confused-tiger",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:16.241947Z",
     "iopub.status.busy": "2021-05-24T08:52:16.239953Z",
     "iopub.status.idle": "2021-05-24T08:52:16.251452Z",
     "shell.execute_reply": "2021-05-24T08:52:16.250826Z"
    },
    "papermill": {
     "duration": 0.053241,
     "end_time": "2021-05-24T08:52:16.251605",
     "exception": false,
     "start_time": "2021-05-24T08:52:16.198364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "#mode = 'predict'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-lawrence",
   "metadata": {
    "papermill": {
     "duration": 0.036129,
     "end_time": "2021-05-24T08:52:16.323427",
     "exception": false,
     "start_time": "2021-05-24T08:52:16.287298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### For **mode = 'train**',\n",
    "1) Add data --> Competitions Data --> Search for \"VinBigData Chest X-ray Abnormalities Detection\" </br>\n",
    "2) Add data --> Datasets --> Search for \"vinbigdata-chest-xray-original-png\"</br>\n",
    "3) Enable the GPU in the Settings --> Accelarator --> GPU</br>\n",
    "The output of the mode is \"detr_model.pth\"</br>\n",
    "\n",
    "#### For **mode = 'predict'**, \n",
    "1) Go to the outputs of the previous mode (train mode \"detr_model.pth\"), select \"Add new version\" and keep the created URL</br>\n",
    "2) Go back to Kaggle's notebook --> Add data --> Datasets --> Search by URL with the saved URL from the last step</br>\n",
    "3) Î•nable the CPU in the Settings --> Accelarator --> CPU</br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-infrared",
   "metadata": {
    "papermill": {
     "duration": 0.036024,
     "end_time": "2021-05-24T08:52:16.396165",
     "exception": false,
     "start_time": "2021-05-24T08:52:16.360141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "julian-bristol",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:16.492307Z",
     "iopub.status.busy": "2021-05-24T08:52:16.491573Z",
     "iopub.status.idle": "2021-05-24T08:52:44.467716Z",
     "shell.execute_reply": "2021-05-24T08:52:44.476976Z"
    },
    "papermill": {
     "duration": 28.045003,
     "end_time": "2021-05-24T08:52:44.477324",
     "exception": false,
     "start_time": "2021-05-24T08:52:16.432321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'detr'...\r\n",
      "remote: Enumerating objects: 243, done.\u001b[K\r\n",
      "remote: Total 243 (delta 0), reused 0 (delta 0), pack-reused 243\u001b[K\r\n",
      "Receiving objects: 100% (243/243), 12.84 MiB | 13.66 MiB/s, done.\r\n",
      "Resolving deltas: 100% (127/127), done.\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ensemble_boxes\r\n",
      "  Downloading ensemble_boxes-1.0.6-py3-none-any.whl (20 kB)\r\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from ensemble_boxes) (0.53.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from ensemble_boxes) (1.19.5)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from ensemble_boxes) (1.1.5)\r\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba->ensemble_boxes) (0.36.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba->ensemble_boxes) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->ensemble_boxes) (2.8.1)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->ensemble_boxes) (2021.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->ensemble_boxes) (1.15.0)\r\n",
      "Installing collected packages: ensemble-boxes\r\n",
      "Successfully installed ensemble-boxes-1.0.6\r\n",
      "Collecting map_boxes\r\n",
      "  Downloading map_boxes-1.0.5-py3-none-any.whl (5.1 kB)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from map_boxes) (1.1.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from map_boxes) (1.19.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->map_boxes) (2.8.1)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->map_boxes) (2021.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->map_boxes) (1.15.0)\r\n",
      "Installing collected packages: map-boxes\r\n",
      "Successfully installed map-boxes-1.0.5\r\n"
     ]
    }
   ],
   "source": [
    "# clone github repo of detr\n",
    "!git clone https://github.com/facebookresearch/detr.git   \n",
    "\n",
    "# general libraries\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm.autonotebook import tqdm\n",
    "import re\n",
    "import pydicom\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# torch.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "\n",
    "# CV\n",
    "import cv2\n",
    "\n",
    "# DETR FUCNTIONS FOR LOSS\n",
    "import sys\n",
    "sys.path.append('./detr/')\n",
    "\n",
    "from detr.models.matcher import HungarianMatcher\n",
    "from detr.models.detr import SetCriterion\n",
    "\n",
    "# albumenatations\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "# Glob\n",
    "from glob import glob\n",
    "\n",
    "# ensembling \n",
    "!pip install ensemble_boxes\n",
    "from tqdm import tqdm\n",
    "from ensemble_boxes import *\n",
    "\n",
    "# mAP\n",
    "!pip install map_boxes \n",
    "from map_boxes import mean_average_precision_for_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "soviet-resident",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:44.644963Z",
     "iopub.status.busy": "2021-05-24T08:52:44.643887Z",
     "iopub.status.idle": "2021-05-24T08:52:44.649486Z",
     "shell.execute_reply": "2021-05-24T08:52:44.650279Z"
    },
    "papermill": {
     "duration": 0.092297,
     "end_time": "2021-05-24T08:52:44.650549",
     "exception": false,
     "start_time": "2021-05-24T08:52:44.558252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# thoracic abnormalities (classes)\n",
    "CLASSES = [\n",
    "    'Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Consolidation',\n",
    "    'ILD', 'Infiltration', 'Lung Opacity', 'Nodule/Mass', 'Other lesion', \n",
    "    'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'No Finding'\n",
    "]\n",
    "\n",
    "# colors for visualization\n",
    "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-lying",
   "metadata": {
    "papermill": {
     "duration": 0.074126,
     "end_time": "2021-05-24T08:52:44.799201",
     "exception": false,
     "start_time": "2021-05-24T08:52:44.725075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Preprocessing image metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "built-balance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:44.958515Z",
     "iopub.status.busy": "2021-05-24T08:52:44.955934Z",
     "iopub.status.idle": "2021-05-24T08:52:44.959436Z",
     "shell.execute_reply": "2021-05-24T08:52:44.960383Z"
    },
    "papermill": {
     "duration": 0.087159,
     "end_time": "2021-05-24T08:52:44.960624",
     "exception": false,
     "start_time": "2021-05-24T08:52:44.873465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_images():\n",
    "    # read the images with size 512x512 \n",
    "    # add the dataset in the data section if it is not added yet\n",
    "    train_df = pd.read_csv('../input/vinbigdata-512-image-dataset/vinbigdata/train.csv')\n",
    "    train_df.fillna(0, inplace=True)\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-street",
   "metadata": {
    "papermill": {
     "duration": 0.07264,
     "end_time": "2021-05-24T08:52:45.107878",
     "exception": false,
     "start_time": "2021-05-24T08:52:45.035238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.1 Scale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "further-julian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:45.266607Z",
     "iopub.status.busy": "2021-05-24T08:52:45.265695Z",
     "iopub.status.idle": "2021-05-24T08:52:45.271176Z",
     "shell.execute_reply": "2021-05-24T08:52:45.272169Z"
    },
    "papermill": {
     "duration": 0.092874,
     "end_time": "2021-05-24T08:52:45.272474",
     "exception": false,
     "start_time": "2021-05-24T08:52:45.179600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_images(train_df):\n",
    "    # scale the coordinates of the bounding boxes from their initial values to fit the 512x512 images\n",
    "    # set to the images with no object (class 14), bounding box with coordinates [xmin=0 ymin=0 xmax=1 ymax=1]\n",
    "    train_df.loc[train_df[\"class_id\"] == 14, ['x_max', 'y_max']] = 1.0\n",
    "    train_df.loc[train_df[\"class_id\"] == 14, ['x_min', 'y_min']] = 0\n",
    "\n",
    "    # scale the input image coordinates to fit 512x512 image\n",
    "    IMG_SIZE = 512\n",
    "    train_df['xmin'] = (train_df['x_min']/train_df['width'])*IMG_SIZE\n",
    "    train_df['ymin'] = (train_df['y_min']/train_df['height'])*IMG_SIZE\n",
    "    train_df['xmax'] = (train_df['x_max']/train_df['width'])*IMG_SIZE\n",
    "    train_df['ymax'] = (train_df['y_max']/train_df['height'])*IMG_SIZE\n",
    "\n",
    "    # set to the images with no object (class 14), bounding box with coordinates [xmin=0 ymin=0 xmax=1 ymax=1]\n",
    "    train_df.loc[train_df[\"class_id\"] == 14, ['xmax', 'ymax']] = 1.0\n",
    "    train_df.loc[train_df[\"class_id\"] == 14, ['xmin', 'ymin']] = 0\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-combining",
   "metadata": {
    "papermill": {
     "duration": 0.079526,
     "end_time": "2021-05-24T08:52:45.430951",
     "exception": false,
     "start_time": "2021-05-24T08:52:45.351425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.2 Define folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "addressed-subsection",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:45.603127Z",
     "iopub.status.busy": "2021-05-24T08:52:45.600354Z",
     "iopub.status.idle": "2021-05-24T08:52:45.607039Z",
     "shell.execute_reply": "2021-05-24T08:52:45.608475Z"
    },
    "papermill": {
     "duration": 0.097763,
     "end_time": "2021-05-24T08:52:45.608712",
     "exception": false,
     "start_time": "2021-05-24T08:52:45.510949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_folds(train_df):\n",
    "    unique_images = train_df[\"image_id\"].unique()\n",
    "    df_split = pd.DataFrame(unique_images, columns = ['unique_images']) \n",
    "\n",
    "    # create one column with the number of fold (for the k-fold cross validation)\n",
    "    df_split[\"kfold\"] = -1\n",
    "    df_split = df_split.sample(frac=1).reset_index(drop=True)\n",
    "    y = df_split.unique_images.values\n",
    "    kf = model_selection.GroupKFold(n_splits=5)\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=df_split, y=y, groups=df_split.unique_images.values)):\n",
    "        df_split.loc[v_, \"kfold\"] = f\n",
    "\n",
    "    # annotated boxes from same \"image id\" (image) should be in the same fold [during training each image with its boxes is as one input]\n",
    "    train_df[\"kfold\"] = -1\n",
    "    for ind in train_df.index: \n",
    "         train_df[\"kfold\"][ind] = df_split.loc[ df_split[\"unique_images\"] ==  train_df[\"image_id\"][ind]][\"kfold\"]\n",
    "\n",
    "    train_df.set_index('image_id', inplace=True)\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-creek",
   "metadata": {
    "papermill": {
     "duration": 0.078941,
     "end_time": "2021-05-24T08:52:45.783951",
     "exception": false,
     "start_time": "2021-05-24T08:52:45.705010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.3 Weight boxes fusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dietary-binary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:45.919267Z",
     "iopub.status.busy": "2021-05-24T08:52:45.916951Z",
     "iopub.status.idle": "2021-05-24T08:52:45.920273Z",
     "shell.execute_reply": "2021-05-24T08:52:45.920875Z"
    },
    "papermill": {
     "duration": 0.071915,
     "end_time": "2021-05-24T08:52:45.921042",
     "exception": false,
     "start_time": "2021-05-24T08:52:45.849127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def boxes_fusion(df):\n",
    "    # apply weighted boxes fusion for ensemling overlapping annotated boxes\n",
    "    # Default WBF config \n",
    "    iou_thr = 0.75\n",
    "    skip_box_thr = 0.0001\n",
    "    sigma = 0.1\n",
    "    results = []\n",
    "    image_ids = df.index.unique()\n",
    "   \n",
    "    for image_id in tqdm(image_ids, total=len(image_ids)):\n",
    "        # All annotations for the current image.\n",
    "        data = df[df.index == image_id]\n",
    "        kfold = data['kfold'].unique()[0]\n",
    "        data = data.reset_index(drop=True)\n",
    "        \n",
    "        # WBF expects the coordinates in 0-1 range.\n",
    "        max_value = data.iloc[:, 4:].values.max()\n",
    "        data.loc[:, [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]] = data.iloc[:, 4:] / max_value\n",
    "        #print(\"data\",data)\n",
    "        if data.class_id.unique()[0] !=14:\n",
    "            annotations = {}\n",
    "            weights = []\n",
    "            # Loop through all of the annotations\n",
    "            for idx, row in data.iterrows():\n",
    "                rad_id = row[\"rad_id\"]\n",
    "                if rad_id not in annotations:\n",
    "                    annotations[rad_id] = {\n",
    "                        \"boxes_list\": [],\n",
    "                        \"scores_list\": [],\n",
    "                        \"labels_list\": [],\n",
    "                    }\n",
    "                    # We consider all of the radiologists as equal.\n",
    "                    weights.append(1.0)\n",
    "                annotations[rad_id][\"boxes_list\"].append([row[\"xmin\"], row[\"ymin\"], row[\"xmax\"], row[\"ymax\"]])\n",
    "                annotations[rad_id][\"scores_list\"].append(1.0)\n",
    "                annotations[rad_id][\"labels_list\"].append(row[\"class_id\"])\n",
    "\n",
    "            boxes_list = []\n",
    "            scores_list = []\n",
    "            labels_list = []\n",
    "\n",
    "            for annotator in annotations.keys():\n",
    "                boxes_list.append(annotations[annotator][\"boxes_list\"])\n",
    "                scores_list.append(annotations[annotator][\"scores_list\"])\n",
    "                labels_list.append(annotations[annotator][\"labels_list\"])\n",
    "\n",
    "            # Calculate WBF\n",
    "            boxes, scores, labels = weighted_boxes_fusion(boxes_list,\n",
    "                scores_list,\n",
    "                labels_list,\n",
    "                weights=weights,\n",
    "                iou_thr=iou_thr,\n",
    "                skip_box_thr=skip_box_thr\n",
    "            )\n",
    "            for idx, box in enumerate(boxes):\n",
    "                results.append({\n",
    "                    \"image_id\": image_id,\n",
    "                    \"class_id\": int(labels[idx]),\n",
    "                    \"rad_id\": \"wbf\",\n",
    "                    \"xmin\": box[0]* max_value,\n",
    "                    \"ymin\": box[1]* max_value,\n",
    "                    \"xmax\": box[2]* max_value,\n",
    "                    \"ymax\": box[3]* max_value,\n",
    "                    \"kfold\":kfold,\n",
    "                })\n",
    "        # if class is nothing then have it once (instead of 3 times in the same image)\n",
    "        if data.class_id.unique()[0] ==14:\n",
    "            for idx, box in enumerate([0]):\n",
    "                results.append({\n",
    "                    \"image_id\": image_id,\n",
    "                    \"class_id\": data.class_id[0],\n",
    "                    \"rad_id\": \"wbf\",\n",
    "                    \"xmin\": 0,\n",
    "                    \"ymin\": 0,\n",
    "                    \"xmax\": 1,\n",
    "                    \"ymax\": 1,\n",
    "                    \"kfold\":kfold,\n",
    "                })\n",
    "            \n",
    "    results = pd.DataFrame(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-blackjack",
   "metadata": {
    "papermill": {
     "duration": 0.045971,
     "end_time": "2021-05-24T08:52:46.013672",
     "exception": false,
     "start_time": "2021-05-24T08:52:45.967701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.4 Pascal to coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "patient-information",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:46.118591Z",
     "iopub.status.busy": "2021-05-24T08:52:46.116420Z",
     "iopub.status.idle": "2021-05-24T08:52:46.119783Z",
     "shell.execute_reply": "2021-05-24T08:52:46.120345Z"
    },
    "papermill": {
     "duration": 0.059618,
     "end_time": "2021-05-24T08:52:46.120522",
     "exception": false,
     "start_time": "2021-05-24T08:52:46.060904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pascal_to_coco(train_df):\n",
    "    # Good exlanation of coco, pascal etc \n",
    "    # https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/\n",
    "    train_df['coco_x'] = train_df['xmin'] + (train_df['xmax'] - train_df['xmin'] )/2\n",
    "    train_df['coco_y'] = train_df['ymin'] + (train_df['ymax'] - train_df['ymin'] )/2\n",
    "    train_df['coco_w'] = train_df['xmax'] - train_df['xmin'] \n",
    "    train_df['coco_h'] = train_df['ymax'] - train_df['ymin'] \n",
    "\n",
    "    train_df.loc[train_df['class_id'] == 14, 'coco_x'] = 1\n",
    "    train_df.loc[train_df['class_id'] == 14, 'coco_y'] = 1\n",
    "    train_df.loc[train_df['class_id'] == 14, 'coco_w'] = 0.5\n",
    "    train_df.loc[train_df['class_id'] == 14, 'coco_h'] = 0.5\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-inflation",
   "metadata": {
    "papermill": {
     "duration": 0.047144,
     "end_time": "2021-05-24T08:52:46.216882",
     "exception": false,
     "start_time": "2021-05-24T08:52:46.169738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.5 Main preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "compatible-prior",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:46.321233Z",
     "iopub.status.busy": "2021-05-24T08:52:46.319034Z",
     "iopub.status.idle": "2021-05-24T08:52:46.323280Z",
     "shell.execute_reply": "2021-05-24T08:52:46.322587Z"
    },
    "papermill": {
     "duration": 0.059692,
     "end_time": "2021-05-24T08:52:46.323488",
     "exception": false,
     "start_time": "2021-05-24T08:52:46.263796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing():\n",
    "    train_df = read_images()\n",
    "    train_df = scale_images(train_df)\n",
    "    train_df = define_folds(train_df)\n",
    "    train_df = boxes_fusion(train_df)\n",
    "    train_df.set_index('image_id', inplace=True)\n",
    "    train_df = pascal_to_coco(train_df)\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-hospital",
   "metadata": {
    "papermill": {
     "duration": 0.047224,
     "end_time": "2021-05-24T08:52:46.419065",
     "exception": false,
     "start_time": "2021-05-24T08:52:46.371841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Creating Image Dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cloudy-jewelry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:46.524302Z",
     "iopub.status.busy": "2021-05-24T08:52:46.522027Z",
     "iopub.status.idle": "2021-05-24T08:52:46.525038Z",
     "shell.execute_reply": "2021-05-24T08:52:46.525817Z"
    },
    "papermill": {
     "duration": 0.05955,
     "end_time": "2021-05-24T08:52:46.526009",
     "exception": false,
     "start_time": "2021-05-24T08:52:46.466459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    # image augmentations for the training set\n",
    "    return A.Compose([A.ToGray(p=0.01),\n",
    "                      A.Cutout(num_holes=10, max_h_size=32, max_w_size=32, fill_value=0, p=0.5),\n",
    "                      ToTensorV2(p=1.0)],\n",
    "                      p=1.0,\n",
    "                      bbox_params=A.BboxParams(format='coco',min_area=0, min_visibility=0,label_fields=['labels'])\n",
    "                      )\n",
    "\n",
    "def get_valid_transforms():\n",
    "    # image augmentations for the validation set\n",
    "    return A.Compose([ToTensorV2(p=1.0)], \n",
    "                      p=1.0, \n",
    "                      bbox_params=A.BboxParams(format='coco',min_area=0, min_visibility=0,label_fields=['labels'])\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "arctic-verse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:46.633918Z",
     "iopub.status.busy": "2021-05-24T08:52:46.633153Z",
     "iopub.status.idle": "2021-05-24T08:52:46.638361Z",
     "shell.execute_reply": "2021-05-24T08:52:46.637651Z"
    },
    "papermill": {
     "duration": 0.064674,
     "end_time": "2021-05-24T08:52:46.638481",
     "exception": false,
     "start_time": "2021-05-24T08:52:46.573807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR_TRAIN = '../input/vinbigdata-chest-xray-abnormalities-detection/train'\n",
    "DIR_TRAIN_PNG = '../input/vinbigdata-512-image-dataset/vinbigdata/train'\n",
    "\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "class VinDataset(Dataset):\n",
    "    def __init__(self,image_ids,dataframe,transforms=None):\n",
    "        self.image_ids = image_ids\n",
    "        self.df = dataframe\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        image_id = self.image_ids[index]\n",
    "        records = self.df.loc[image_id]\n",
    "        labels = records['class_id']\n",
    "        \n",
    "        image = cv2.imread(f'{DIR_TRAIN_PNG}/{image_id}.png', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        \n",
    "        # DETR takes in data in coco format    \n",
    "        boxes = records[['coco_x', 'coco_y', 'coco_w', 'coco_h']].values\n",
    "     \n",
    "        # AS pointed out by PRVI It works better if the main class is labelled as zero\n",
    "        labels =  np.array(labels)\n",
    "    \n",
    "        if boxes.ndim == 1 : \n",
    "            boxes = np.expand_dims(boxes, axis=0)\n",
    "            labels = np.expand_dims(labels, axis=0)\n",
    "        \n",
    "        # AS pointed out by PRVI It works better if the main class is labelled as zero\n",
    "        labels =  np.array(labels)\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': boxes,\n",
    "                'labels': labels\n",
    "            }\n",
    "\n",
    "        sample = self.transforms(**sample)\n",
    "        image = sample['image']\n",
    "        boxes = sample['bboxes']\n",
    "        labels = sample['labels']\n",
    "        \n",
    "        # Normalizing BBOXES\n",
    "        _,h,w = image.shape\n",
    "        boxes = A.augmentations.bbox_utils.normalize_bboxes(sample['bboxes'],rows=h,cols=w)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = torch.as_tensor(boxes,dtype=torch.float32)\n",
    "        target['labels'] = torch.as_tensor(labels,dtype=torch.long)\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "\n",
    "        return image/255, target, image_id    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-participant",
   "metadata": {
    "papermill": {
     "duration": 0.047203,
     "end_time": "2021-05-24T08:52:46.732196",
     "exception": false,
     "start_time": "2021-05-24T08:52:46.684993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. DETR model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "million-producer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:46.838287Z",
     "iopub.status.busy": "2021-05-24T08:52:46.835943Z",
     "iopub.status.idle": "2021-05-24T08:52:46.839150Z",
     "shell.execute_reply": "2021-05-24T08:52:46.839863Z"
    },
    "papermill": {
     "duration": 0.060856,
     "end_time": "2021-05-24T08:52:46.840033",
     "exception": false,
     "start_time": "2021-05-24T08:52:46.779177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class DETRModel(nn.Module):\n",
    "    def __init__(self,num_classes,num_queries):\n",
    "        super(DETRModel,self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_queries = num_queries\n",
    "        self.model = torch.hub.load('facebookresearch/detr', 'detr_resnet50', pretrained=True)\n",
    "        \n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "        self.in_features = self.model.class_embed.in_features\n",
    "        \n",
    "        self.model.class_embed = nn.Linear(in_features=self.in_features,out_features=self.num_classes+1)\n",
    "        self.model.num_queries = self.num_queries\n",
    "        \n",
    "    def forward(self,images):\n",
    "        return self.model(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-illness",
   "metadata": {
    "papermill": {
     "duration": 0.04708,
     "end_time": "2021-05-24T08:52:46.934690",
     "exception": false,
     "start_time": "2021-05-24T08:52:46.887610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Modeling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-township",
   "metadata": {
    "papermill": {
     "duration": 0.047383,
     "end_time": "2021-05-24T08:52:47.030026",
     "exception": false,
     "start_time": "2021-05-24T08:52:46.982643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6.1 Average meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "changed-malta",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:47.132675Z",
     "iopub.status.busy": "2021-05-24T08:52:47.131550Z",
     "iopub.status.idle": "2021-05-24T08:52:47.134834Z",
     "shell.execute_reply": "2021-05-24T08:52:47.134296Z"
    },
    "papermill": {
     "duration": 0.057716,
     "end_time": "2021-05-24T08:52:47.135049",
     "exception": false,
     "start_time": "2021-05-24T08:52:47.077333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AverageMeter - class for averaging loss,metric,etc over epochs\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-finder",
   "metadata": {
    "papermill": {
     "duration": 0.047128,
     "end_time": "2021-05-24T08:52:47.230669",
     "exception": false,
     "start_time": "2021-05-24T08:52:47.183541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6.2 Training Function\n",
    "\n",
    "Training of DETR is unique and different from FasteRRcnn  and EfficientDET , as we train the criterion as well , the training function can be viewed here : https://github.com/facebookresearch/detr/blob/master/engine.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alternative-pride",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:47.337825Z",
     "iopub.status.busy": "2021-05-24T08:52:47.336655Z",
     "iopub.status.idle": "2021-05-24T08:52:47.340151Z",
     "shell.execute_reply": "2021-05-24T08:52:47.339629Z"
    },
    "papermill": {
     "duration": 0.062042,
     "end_time": "2021-05-24T08:52:47.340291",
     "exception": false,
     "start_time": "2021-05-24T08:52:47.278249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(data_loader,model,criterion,optimizer,device,scheduler,epoch):\n",
    "    model.train()\n",
    "    criterion.train()\n",
    "    \n",
    "    summary_loss = AverageMeter()\n",
    "    \n",
    "    tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "    \n",
    "    check_repeats = []\n",
    "    for step, (images, targets, image_ids) in enumerate(tk0):\n",
    "            if image_ids in check_repeats:\n",
    "                continue\n",
    "            else:\n",
    "                check_repeats.append(image_ids)\n",
    "\n",
    "                images = list(image.to(device) for image in images)\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                #print(\"images : {}\".format(images))\n",
    "\n",
    "                output = model(images)\n",
    "\n",
    "                loss_dict = criterion(output, targets)\n",
    "                weight_dict = criterion.weight_dict\n",
    "\n",
    "                losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                losses.backward()\n",
    "                optimizer.step()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "\n",
    "                summary_loss.update(losses.item(),BATCH_SIZE)\n",
    "                tk0.set_postfix(loss=summary_loss.avg)\n",
    "\n",
    "    return summary_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-reach",
   "metadata": {
    "papermill": {
     "duration": 0.048004,
     "end_time": "2021-05-24T08:52:47.436591",
     "exception": false,
     "start_time": "2021-05-24T08:52:47.388587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6.3 Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "liked-twist",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:47.535886Z",
     "iopub.status.busy": "2021-05-24T08:52:47.534972Z",
     "iopub.status.idle": "2021-05-24T08:52:47.537953Z",
     "shell.execute_reply": "2021-05-24T08:52:47.538562Z"
    },
    "papermill": {
     "duration": 0.057125,
     "end_time": "2021-05-24T08:52:47.538773",
     "exception": false,
     "start_time": "2021-05-24T08:52:47.481648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32).to(device='cuda')\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fewer-culture",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:47.632662Z",
     "iopub.status.busy": "2021-05-24T08:52:47.631531Z",
     "iopub.status.idle": "2021-05-24T08:52:47.653220Z",
     "shell.execute_reply": "2021-05-24T08:52:47.652690Z"
    },
    "papermill": {
     "duration": 0.069995,
     "end_time": "2021-05-24T08:52:47.653364",
     "exception": false,
     "start_time": "2021-05-24T08:52:47.583369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model,criterion, device):\n",
    "    model.eval()\n",
    "    criterion.eval()\n",
    "    summary_loss = AverageMeter()\n",
    "    map_df = pd.DataFrame()\n",
    "    map_df_target = pd.DataFrame()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        check_repeats_val = []\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader))\n",
    "        for step, (images, targets, image_ids) in enumerate(tk0):\n",
    "            if image_ids in check_repeats_val:\n",
    "                continue\n",
    "            else:\n",
    "                check_repeats_val.append(image_ids)\n",
    "\n",
    "                images = list(image.to(device) for image in images)\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                outputs = model(images)\n",
    "\n",
    "                # MAP targets\n",
    "                for count, label in enumerate(targets[0]['labels']):\n",
    "                    text = f'{CLASSES[label]}' \n",
    "                    xmin = targets[0]['boxes'][count][0] - (targets[0]['boxes'][count][2])/2\n",
    "                    xmax = targets[0]['boxes'][count][0] + (targets[0]['boxes'][count][2])/2  \n",
    "                    ymin = targets[0]['boxes'][count][1] - (targets[0]['boxes'][count][3])/2\n",
    "                    ymax = targets[0]['boxes'][count][1] + (targets[0]['boxes'][count][3])/2\n",
    "\n",
    "                    data = pd.DataFrame({\"ImageID\": [image_ids[0]],\"LabelName\": [text],\n",
    "                    \"XMin\": [xmin.item()], \"XMax\": [xmax.item()], \"YMin\": [ymin.item()], \"YMax\": [ymax.item()]})\n",
    "                    map_df_target = map_df_target.append(data)                \n",
    "\n",
    "                probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
    "                keep = probas.max(-1).values > 0.08\n",
    "                boxes = rescale_bboxes(outputs['pred_boxes'][0, keep], (512,512))\n",
    "                prob = probas[keep]\n",
    "\n",
    "                colors = COLORS * 100\n",
    "                for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n",
    "\n",
    "                    cl = p.argmax()\n",
    "                    text = f'{CLASSES[cl]}' \n",
    "                    \n",
    "                    # Dataframe for MAP\n",
    "                    data = pd.DataFrame({\"ImageID\": [image_ids[0]],\"LabelName\": [text], \"Conf\": [p[cl].item()], \"XMin\": [xmin/512], \"XMax\": [xmax/512], \"YMin\": [ymin/512], \"YMax\": [ymax/512]})\n",
    "                    map_df = map_df.append(data)          \n",
    "\n",
    "                loss_dict = criterion(outputs, targets)\n",
    "                weight_dict = criterion.weight_dict\n",
    "\n",
    "                losses = sum(loss_dict[k] * weight_dict[k] for k in loss_dict.keys() if k in weight_dict)\n",
    "\n",
    "                summary_loss.update(losses.item(),BATCH_SIZE)\n",
    "                tk0.set_postfix(loss=summary_loss.avg)\n",
    "        \n",
    "        ann = map_df_target[['ImageID', 'LabelName', 'XMin', 'XMax', 'YMin', 'YMax']].values\n",
    "        det = map_df[['ImageID', 'LabelName', 'Conf', 'XMin', 'XMax', 'YMin', 'YMax']].values\n",
    "        mean_ap, average_precisions = mean_average_precision_for_boxes(ann, det, iou_threshold=0.4)\n",
    "\n",
    "        print(\"mean_ap : {}\".format(mean_ap))\n",
    "        print(\"average_precisions : {}\".format(average_precisions))\n",
    "        \n",
    "    return summary_loss, mean_ap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-duplicate",
   "metadata": {
    "papermill": {
     "duration": 0.044903,
     "end_time": "2021-05-24T08:52:47.743824",
     "exception": false,
     "start_time": "2021-05-24T08:52:47.698921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6.4 Run DETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "spiritual-layout",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:47.840079Z",
     "iopub.status.busy": "2021-05-24T08:52:47.839430Z",
     "iopub.status.idle": "2021-05-24T08:52:47.843828Z",
     "shell.execute_reply": "2021-05-24T08:52:47.844341Z"
    },
    "papermill": {
     "duration": 0.055098,
     "end_time": "2021-05-24T08:52:47.844527",
     "exception": false,
     "start_time": "2021-05-24T08:52:47.789429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "suburban-dividend",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:47.952534Z",
     "iopub.status.busy": "2021-05-24T08:52:47.951434Z",
     "iopub.status.idle": "2021-05-24T08:52:47.958038Z",
     "shell.execute_reply": "2021-05-24T08:52:47.957509Z"
    },
    "papermill": {
     "duration": 0.067047,
     "end_time": "2021-05-24T08:52:47.958187",
     "exception": false,
     "start_time": "2021-05-24T08:52:47.891140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(train_df, fold):\n",
    "            \n",
    "    df_train = train_df[train_df['kfold'] != fold]\n",
    "    df_valid = train_df[train_df['kfold'] == fold]\n",
    "\n",
    "    train_dataset = VinDataset(\n",
    "    image_ids=df_train.index.values,\n",
    "    dataframe=df_train,\n",
    "    transforms=get_train_transforms()\n",
    "    )\n",
    "\n",
    "    valid_dataset = VinDataset(\n",
    "    image_ids=df_valid.index.values,\n",
    "    dataframe=df_valid,\n",
    "    transforms=get_valid_transforms()\n",
    "    )\n",
    "    \n",
    "    train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    "    )\n",
    "    \n",
    "    # Bipartite Matching Loss\n",
    "    matcher = HungarianMatcher()\n",
    "    weight_dict = weight_dict = {'loss_ce': 1, 'loss_bbox': 1 , 'loss_giou': 1}\n",
    "    losses = ['labels', 'boxes', 'cardinality']\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    model = DETRModel(num_classes=num_classes,num_queries=num_queries)\n",
    "    model = model.to(device)\n",
    "    criterion = SetCriterion(num_classes, matcher, weight_dict, eos_coef = null_class_coef, losses=losses)\n",
    "    criterion = criterion.to(device)\n",
    "    \n",
    "    LR = 3e-5\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "   \n",
    "    best_loss = 0\n",
    "    val_loss_track_switch = 0\n",
    "    all_train_losses = []\n",
    "    all_valid_losses = []\n",
    "    all_mean_ap = []\n",
    "    columns = ['train_losses', 'valid_losses', 'mean_ap']\n",
    "    df_losses = pd.DataFrame(columns = columns )\n",
    "    df_losses.to_csv(\"all_losses.csv\",mode='a', index=False)\n",
    "    for epoch in range(EPOCHS):\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "        train_loss = train_fn(train_data_loader, model,criterion, optimizer,device,scheduler=None,epoch=epoch)\n",
    "        if val_loss_track_switch % 2 == 0: \n",
    "            LR = LR/1.12        \n",
    "            valid_loss, map_validation = eval_fn(valid_data_loader, model,criterion, device)\n",
    "        val_loss_track_switch = val_loss_track_switch + 1\n",
    "        \n",
    "        df_losses = df_losses.append({'train_losses': train_loss.avg,'valid_losses': valid_loss.avg,'mean_ap': map_validation}, ignore_index=True)\n",
    "        df_losses.to_csv(\"all_losses.csv\",index=False, header=False,mode='a')\n",
    "        df_losses.drop(df_losses.tail(1).index,inplace=True)\n",
    "        \n",
    "        print('|EPOCH {}| TRAIN_LOSS {}| VALID_LOSS {}|'.format(epoch+1,train_loss.avg,valid_loss.avg))\n",
    "        \n",
    "        if map_validation > best_loss:\n",
    "            best_loss = map_validation\n",
    "            print('Best model found for Fold {} in Epoch {}........Saving Model'.format(fold,epoch+1))\n",
    "            torch.save(model.state_dict(), f'detr_model.pth')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-pierce",
   "metadata": {
    "papermill": {
     "duration": 0.045771,
     "end_time": "2021-05-24T08:52:48.048893",
     "exception": false,
     "start_time": "2021-05-24T08:52:48.003122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Main training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "desperate-module",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:48.145979Z",
     "iopub.status.busy": "2021-05-24T08:52:48.144981Z",
     "iopub.status.idle": "2021-05-24T08:52:48.148494Z",
     "shell.execute_reply": "2021-05-24T08:52:48.147787Z"
    },
    "papermill": {
     "duration": 0.054352,
     "end_time": "2021-05-24T08:52:48.148635",
     "exception": false,
     "start_time": "2021-05-24T08:52:48.094283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "seed = 42\n",
    "num_classes = 15\n",
    "num_queries = 2\n",
    "null_class_coef = 0.2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceramic-theory",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:48.245904Z",
     "iopub.status.busy": "2021-05-24T08:52:48.244844Z",
     "iopub.status.idle": "2021-05-24T08:52:48.248601Z",
     "shell.execute_reply": "2021-05-24T08:52:48.248010Z",
     "shell.execute_reply.started": "2021-05-21T12:41:37.077213Z"
    },
    "papermill": {
     "duration": 0.054609,
     "end_time": "2021-05-24T08:52:48.248733",
     "exception": false,
     "start_time": "2021-05-24T08:52:48.194124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_training():\n",
    "    train_df = preprocessing()\n",
    "    import torch, gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # run this function for training the model\n",
    "    model = run(train_df, fold=0)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "combined-antique",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T08:52:48.357763Z",
     "iopub.status.busy": "2021-05-24T08:52:48.357096Z",
     "iopub.status.idle": "2021-05-24T17:18:20.838599Z",
     "shell.execute_reply": "2021-05-24T17:18:20.837932Z"
    },
    "papermill": {
     "duration": 30332.544058,
     "end_time": "2021-05-24T17:18:20.838778",
     "exception": false,
     "start_time": "2021-05-24T08:52:48.294720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15000/15000 [03:19<00:00, 75.06it/s]\n",
      "Downloading: \"https://github.com/facebookresearch/detr/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf666970a7e42fb9a9c43196e6f2673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth\" to /root/.cache/torch/hub/checkpoints/detr-r50-e632da11.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2525c1a7425647519937e613d2e5d314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/159M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [26:57<00:00,  1.57s/it, loss=1.83]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8402/8402 [08:13<00:00, 17.01it/s, loss=1.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in annotations: 3000\n",
      "Number of files in predictions: 3000\n",
      "Unique classes: 15\n",
      "Detections length: 3000\n",
      "Annotations length: 3000\n",
      "Aortic enlargement             | 0.166406 |    1100\n",
      "Atelectasis                    | 0.000000 |      52\n",
      "Calcification                  | 0.000000 |     164\n",
      "Cardiomegaly                   | 0.219877 |     763\n",
      "Consolidation                  | 0.000000 |     102\n",
      "ILD                            | 0.032242 |     185\n",
      "Infiltration                   | 0.041741 |     248\n",
      "Lung Opacity                   | 0.038526 |     503\n",
      "No Finding                     | 0.000228 |    2099\n",
      "Nodule/Mass                    | 0.000316 |     502\n",
      "Other lesion                   | 0.000027 |     393\n",
      "Pleural effusion               | 0.078557 |     461\n",
      "Pleural thickening             | 0.029007 |     918\n",
      "Pneumothorax                   | 0.000000 |      26\n",
      "Pulmonary fibrosis             | 0.016541 |     886\n",
      "mAP: 0.041565\n",
      "mean_ap : 0.04156452498219673\n",
      "average_precisions : {'Aortic enlargement': (0.16640642915564618, 1100.0), 'Atelectasis': (0.0, 52.0), 'Calcification': (0.0, 164.0), 'Cardiomegaly': (0.21987728424552413, 763.0), 'Consolidation': (0.0, 102.0), 'ILD': (0.032242314027292926, 185.0), 'Infiltration': (0.04174050475758044, 248.0), 'Lung Opacity': (0.03852573267488215, 503.0), 'No Finding': (0.00022823638651095848, 2099.0), 'Nodule/Mass': (0.00031615515061671835, 502.0), 'Other lesion': (2.6784518548279097e-05, 393.0), 'Pleural effusion': (0.07855660085033601, 461.0), 'Pleural thickening': (0.029006700623667073, 918.0), 'Pneumothorax': (0.0, 26.0), 'Pulmonary fibrosis': (0.01654113234234608, 886.0)}\n",
      "|EPOCH 1| TRAIN_LOSS 1.8260225791820153| VALID_LOSS 1.0564408876945575|\n",
      "Best model found for Fold 0 in Epoch 1........Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:18<00:00,  1.59s/it, loss=1.41]\n",
      "  0%|          | 0/1031 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|EPOCH 2| TRAIN_LOSS 1.4051933574167763| VALID_LOSS 1.0564408876945575|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:28<00:00,  1.60s/it, loss=1.25]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8402/8402 [07:52<00:00, 17.78it/s, loss=0.674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in annotations: 3000\n",
      "Number of files in predictions: 3000\n",
      "Unique classes: 15\n",
      "Detections length: 3000\n",
      "Annotations length: 3000\n",
      "Aortic enlargement             | 0.257461 |    1100\n",
      "Atelectasis                    | 0.038462 |      52\n",
      "Calcification                  | 0.001505 |     164\n",
      "Cardiomegaly                   | 0.239384 |     763\n",
      "Consolidation                  | 0.022701 |     102\n",
      "ILD                            | 0.048808 |     185\n",
      "Infiltration                   | 0.087524 |     248\n",
      "Lung Opacity                   | 0.104214 |     503\n",
      "No Finding                     | 0.982415 |    2099\n",
      "Nodule/Mass                    | 0.012309 |     502\n",
      "Other lesion                   | 0.007792 |     393\n",
      "Pleural effusion               | 0.160226 |     461\n",
      "Pleural thickening             | 0.043079 |     918\n",
      "Pneumothorax                   | 0.000000 |      26\n",
      "Pulmonary fibrosis             | 0.040762 |     886\n",
      "mAP: 0.136443\n",
      "mean_ap : 0.1364428316403826\n",
      "average_precisions : {'Aortic enlargement': (0.25746142869442273, 1100.0), 'Atelectasis': (0.038461538461538464, 52.0), 'Calcification': (0.001504752641342925, 164.0), 'Cardiomegaly': (0.23938387014428658, 763.0), 'Consolidation': (0.02270147099369111, 102.0), 'ILD': (0.048807596467790704, 185.0), 'Infiltration': (0.08752435846916107, 248.0), 'Lung Opacity': (0.10421444583617104, 503.0), 'No Finding': (0.9824150677768129, 2099.0), 'Nodule/Mass': (0.012309323485730606, 502.0), 'Other lesion': (0.00779165476287603, 393.0), 'Pleural effusion': (0.16022588228823076, 461.0), 'Pleural thickening': (0.04307945447404332, 918.0), 'Pneumothorax': (0.0, 26.0), 'Pulmonary fibrosis': (0.04076163010964064, 886.0)}\n",
      "|EPOCH 3| TRAIN_LOSS 1.2527867288524728| VALID_LOSS 0.6735665024270614|\n",
      "Best model found for Fold 0 in Epoch 3........Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:20<00:00,  1.59s/it, loss=1.15]\n",
      "  0%|          | 0/1031 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|EPOCH 4| TRAIN_LOSS 1.1526833414800184| VALID_LOSS 0.6735665024270614|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:22<00:00,  1.59s/it, loss=1.08]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8402/8402 [07:35<00:00, 18.46it/s, loss=0.597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in annotations: 3000\n",
      "Number of files in predictions: 3000\n",
      "Unique classes: 15\n",
      "Detections length: 3000\n",
      "Annotations length: 3000\n",
      "Aortic enlargement             | 0.249572 |    1100\n",
      "Atelectasis                    | 0.051676 |      52\n",
      "Calcification                  | 0.028067 |     164\n",
      "Cardiomegaly                   | 0.325199 |     763\n",
      "Consolidation                  | 0.051275 |     102\n",
      "ILD                            | 0.036273 |     185\n",
      "Infiltration                   | 0.083420 |     248\n",
      "Lung Opacity                   | 0.155373 |     503\n",
      "No Finding                     | 0.991392 |    2099\n",
      "Nodule/Mass                    | 0.028511 |     502\n",
      "Other lesion                   | 0.017012 |     393\n",
      "Pleural effusion               | 0.191579 |     461\n",
      "Pleural thickening             | 0.053559 |     918\n",
      "Pneumothorax                   | 0.000000 |      26\n",
      "Pulmonary fibrosis             | 0.080542 |     886\n",
      "mAP: 0.156230\n",
      "mean_ap : 0.15622996355203783\n",
      "average_precisions : {'Aortic enlargement': (0.24957215634955776, 1100.0), 'Atelectasis': (0.051675663517768776, 52.0), 'Calcification': (0.02806661164635489, 164.0), 'Cardiomegaly': (0.3251993349043039, 763.0), 'Consolidation': (0.05127490804695143, 102.0), 'ILD': (0.03627268980380277, 185.0), 'Infiltration': (0.08342015162333072, 248.0), 'Lung Opacity': (0.15537299466199728, 503.0), 'No Finding': (0.9913921015746494, 2099.0), 'Nodule/Mass': (0.028511404142902035, 502.0), 'Other lesion': (0.01701176689930613, 393.0), 'Pleural effusion': (0.19157858415445092, 461.0), 'Pleural thickening': (0.053558935091441516, 918.0), 'Pneumothorax': (0.0, 26.0), 'Pulmonary fibrosis': (0.0805421508637504, 886.0)}\n",
      "|EPOCH 5| TRAIN_LOSS 1.0760024355292668| VALID_LOSS 0.5971556752473116|\n",
      "Best model found for Fold 0 in Epoch 5........Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:30<00:00,  1.60s/it, loss=1.05]\n",
      "  0%|          | 0/1031 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|EPOCH 6| TRAIN_LOSS 1.047261801827428| VALID_LOSS 0.5971556752473116|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:34<00:00,  1.60s/it, loss=0.966]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8402/8402 [07:35<00:00, 18.46it/s, loss=0.607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in annotations: 3000\n",
      "Number of files in predictions: 3000\n",
      "Unique classes: 15\n",
      "Detections length: 3000\n",
      "Annotations length: 3000\n",
      "Aortic enlargement             | 0.315543 |    1100\n",
      "Atelectasis                    | 0.034349 |      52\n",
      "Calcification                  | 0.026494 |     164\n",
      "Cardiomegaly                   | 0.398345 |     763\n",
      "Consolidation                  | 0.056341 |     102\n",
      "ILD                            | 0.075108 |     185\n",
      "Infiltration                   | 0.076515 |     248\n",
      "Lung Opacity                   | 0.175447 |     503\n",
      "No Finding                     | 0.991072 |    2099\n",
      "Nodule/Mass                    | 0.033573 |     502\n",
      "Other lesion                   | 0.022625 |     393\n",
      "Pleural effusion               | 0.195345 |     461\n",
      "Pleural thickening             | 0.066245 |     918\n",
      "Pneumothorax                   | 0.046154 |      26\n",
      "Pulmonary fibrosis             | 0.079174 |     886\n",
      "mAP: 0.172822\n",
      "mean_ap : 0.17282192677464928\n",
      "average_precisions : {'Aortic enlargement': (0.31554326977280733, 1100.0), 'Atelectasis': (0.03434895535587713, 52.0), 'Calcification': (0.026493596402667727, 164.0), 'Cardiomegaly': (0.3983452787717067, 763.0), 'Consolidation': (0.056340698450587465, 102.0), 'ILD': (0.07510807010519557, 185.0), 'Infiltration': (0.07651539741714056, 248.0), 'Lung Opacity': (0.17544709302216488, 503.0), 'No Finding': (0.9910717545333969, 2099.0), 'Nodule/Mass': (0.033572513560805116, 502.0), 'Other lesion': (0.022624837078914155, 393.0), 'Pleural effusion': (0.19534459513974867, 461.0), 'Pleural thickening': (0.06624455621529013, 918.0), 'Pneumothorax': (0.046153846153846156, 26.0), 'Pulmonary fibrosis': (0.07917443963959087, 886.0)}\n",
      "|EPOCH 7| TRAIN_LOSS 0.9657346414317215| VALID_LOSS 0.6072202308674653|\n",
      "Best model found for Fold 0 in Epoch 7........Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:21<00:00,  1.59s/it, loss=0.893]\n",
      "  0%|          | 0/1031 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|EPOCH 8| TRAIN_LOSS 0.8932075742144358| VALID_LOSS 0.6072202308674653|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:24<00:00,  1.59s/it, loss=0.857]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8402/8402 [07:23<00:00, 18.96it/s, loss=0.597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in annotations: 3000\n",
      "Number of files in predictions: 3000\n",
      "Unique classes: 15\n",
      "Detections length: 3000\n",
      "Annotations length: 3000\n",
      "Aortic enlargement             | 0.340808 |    1100\n",
      "Atelectasis                    | 0.033961 |      52\n",
      "Calcification                  | 0.015439 |     164\n",
      "Cardiomegaly                   | 0.410594 |     763\n",
      "Consolidation                  | 0.058950 |     102\n",
      "ILD                            | 0.062897 |     185\n",
      "Infiltration                   | 0.089212 |     248\n",
      "Lung Opacity                   | 0.169096 |     503\n",
      "No Finding                     | 0.991192 |    2099\n",
      "Nodule/Mass                    | 0.037584 |     502\n",
      "Other lesion                   | 0.018841 |     393\n",
      "Pleural effusion               | 0.162315 |     461\n",
      "Pleural thickening             | 0.074113 |     918\n",
      "Pneumothorax                   | 0.144430 |      26\n",
      "Pulmonary fibrosis             | 0.084799 |     886\n",
      "mAP: 0.179615\n",
      "mean_ap : 0.17961539308478794\n",
      "average_precisions : {'Aortic enlargement': (0.3408077244835862, 1100.0), 'Atelectasis': (0.03396105220467041, 52.0), 'Calcification': (0.015438518852439558, 164.0), 'Cardiomegaly': (0.4105942232650515, 763.0), 'Consolidation': (0.058949949998097655, 102.0), 'ILD': (0.062896549996613, 185.0), 'Infiltration': (0.08921218987758589, 248.0), 'Lung Opacity': (0.16909579549438575, 503.0), 'No Finding': (0.9911915545675983, 2099.0), 'Nodule/Mass': (0.03758442514024898, 502.0), 'Other lesion': (0.018841311059295936, 393.0), 'Pleural effusion': (0.1623152431472255, 461.0), 'Pleural thickening': (0.07411315241807653, 918.0), 'Pneumothorax': (0.14442973805321985, 26.0), 'Pulmonary fibrosis': (0.08479946771372388, 886.0)}\n",
      "|EPOCH 9| TRAIN_LOSS 0.857148317546086| VALID_LOSS 0.5970213085313638|\n",
      "Best model found for Fold 0 in Epoch 9........Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:20<00:00,  1.59s/it, loss=0.804]\n",
      "  0%|          | 0/1031 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|EPOCH 10| TRAIN_LOSS 0.8041205805094929| VALID_LOSS 0.5970213085313638|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:23<00:00,  1.59s/it, loss=0.761]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8402/8402 [07:09<00:00, 19.56it/s, loss=0.541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in annotations: 3000\n",
      "Number of files in predictions: 3000\n",
      "Unique classes: 15\n",
      "Detections length: 3000\n",
      "Annotations length: 3000\n",
      "Aortic enlargement             | 0.355310 |    1100\n",
      "Atelectasis                    | 0.077989 |      52\n",
      "Calcification                  | 0.027728 |     164\n",
      "Cardiomegaly                   | 0.404048 |     763\n",
      "Consolidation                  | 0.066773 |     102\n",
      "ILD                            | 0.087671 |     185\n",
      "Infiltration                   | 0.095920 |     248\n",
      "Lung Opacity                   | 0.159959 |     503\n",
      "No Finding                     | 0.990638 |    2099\n",
      "Nodule/Mass                    | 0.056468 |     502\n",
      "Other lesion                   | 0.027257 |     393\n",
      "Pleural effusion               | 0.173508 |     461\n",
      "Pleural thickening             | 0.078069 |     918\n",
      "Pneumothorax                   | 0.091608 |      26\n",
      "Pulmonary fibrosis             | 0.128547 |     886\n",
      "mAP: 0.188100\n",
      "mean_ap : 0.18809952852511264\n",
      "average_precisions : {'Aortic enlargement': (0.355310310591397, 1100.0), 'Atelectasis': (0.07798916468580223, 52.0), 'Calcification': (0.027727636077334177, 164.0), 'Cardiomegaly': (0.4040476378531086, 763.0), 'Consolidation': (0.06677278462126475, 102.0), 'ILD': (0.08767140782057528, 185.0), 'Infiltration': (0.09591970173478996, 248.0), 'Lung Opacity': (0.15995897451274604, 503.0), 'No Finding': (0.990637839207418, 2099.0), 'Nodule/Mass': (0.05646822853158281, 502.0), 'Other lesion': (0.027257235704738397, 393.0), 'Pleural effusion': (0.17350787339450313, 461.0), 'Pleural thickening': (0.0780688075418981, 918.0), 'Pneumothorax': (0.09160839160839161, 26.0), 'Pulmonary fibrosis': (0.12854693399113928, 886.0)}\n",
      "|EPOCH 11| TRAIN_LOSS 0.7612440202215363| VALID_LOSS 0.5406837738851706|\n",
      "Best model found for Fold 0 in Epoch 11........Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:24<00:00,  1.59s/it, loss=0.721]\n",
      "  0%|          | 0/1031 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|EPOCH 12| TRAIN_LOSS 0.7210818411191613| VALID_LOSS 0.5406837738851706|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:29<00:00,  1.60s/it, loss=0.683]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8402/8402 [07:06<00:00, 19.69it/s, loss=0.564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in annotations: 3000\n",
      "Number of files in predictions: 3000\n",
      "Unique classes: 15\n",
      "Detections length: 3000\n",
      "Annotations length: 3000\n",
      "Aortic enlargement             | 0.302367 |    1100\n",
      "Atelectasis                    | 0.035000 |      52\n",
      "Calcification                  | 0.030430 |     164\n",
      "Cardiomegaly                   | 0.461767 |     763\n",
      "Consolidation                  | 0.069330 |     102\n",
      "ILD                            | 0.102472 |     185\n",
      "Infiltration                   | 0.130909 |     248\n",
      "Lung Opacity                   | 0.167748 |     503\n",
      "No Finding                     | 0.990695 |    2099\n",
      "Nodule/Mass                    | 0.053356 |     502\n",
      "Other lesion                   | 0.022997 |     393\n",
      "Pleural effusion               | 0.173616 |     461\n",
      "Pleural thickening             | 0.081968 |     918\n",
      "Pneumothorax                   | 0.058861 |      26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1031 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulmonary fibrosis             | 0.113781 |     886\n",
      "mAP: 0.186353\n",
      "mean_ap : 0.1863531617615499\n",
      "average_precisions : {'Aortic enlargement': (0.30236698236948156, 1100.0), 'Atelectasis': (0.035000416896779636, 52.0), 'Calcification': (0.03042971067107458, 164.0), 'Cardiomegaly': (0.461767480195517, 763.0), 'Consolidation': (0.06932994389998458, 102.0), 'ILD': (0.1024715786252545, 185.0), 'Infiltration': (0.13090876288054792, 248.0), 'Lung Opacity': (0.1677483658007046, 503.0), 'No Finding': (0.9906951127772421, 2099.0), 'Nodule/Mass': (0.0533558961311547, 502.0), 'Other lesion': (0.022997466461023627, 393.0), 'Pleural effusion': (0.1736156457146926, 461.0), 'Pleural thickening': (0.0819682516084109, 918.0), 'Pneumothorax': (0.05886098028955172, 26.0), 'Pulmonary fibrosis': (0.11378083210182757, 886.0)}\n",
      "|EPOCH 13| TRAIN_LOSS 0.6828983644625148| VALID_LOSS 0.5639672694752613|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:33<00:00,  1.60s/it, loss=0.644]\n",
      "  0%|          | 0/1031 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|EPOCH 14| TRAIN_LOSS 0.644037133160433| VALID_LOSS 0.5639672694752613|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:31<00:00,  1.60s/it, loss=0.61]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8402/8402 [07:05<00:00, 19.77it/s, loss=0.577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in annotations: 3000\n",
      "Number of files in predictions: 3000\n",
      "Unique classes: 15\n",
      "Detections length: 3000\n",
      "Annotations length: 3000\n",
      "Aortic enlargement             | 0.345812 |    1100\n",
      "Atelectasis                    | 0.067731 |      52\n",
      "Calcification                  | 0.045830 |     164\n",
      "Cardiomegaly                   | 0.422661 |     763\n",
      "Consolidation                  | 0.105194 |     102\n",
      "ILD                            | 0.098248 |     185\n",
      "Infiltration                   | 0.145842 |     248\n",
      "Lung Opacity                   | 0.188113 |     503\n",
      "No Finding                     | 0.984940 |    2099\n",
      "Nodule/Mass                    | 0.047277 |     502\n",
      "Other lesion                   | 0.018440 |     393\n",
      "Pleural effusion               | 0.202658 |     461\n",
      "Pleural thickening             | 0.083993 |     918\n",
      "Pneumothorax                   | 0.099135 |      26\n",
      "Pulmonary fibrosis             | 0.109607 |     886\n",
      "mAP: 0.197699\n",
      "mean_ap : 0.1976985478719129\n",
      "average_precisions : {'Aortic enlargement': (0.3458116043611738, 1100.0), 'Atelectasis': (0.06773053593773197, 52.0), 'Calcification': (0.04582963686210727, 164.0), 'Cardiomegaly': (0.42266079913767113, 763.0), 'Consolidation': (0.10519399749546415, 102.0), 'ILD': (0.09824754885208381, 185.0), 'Infiltration': (0.14584181807263852, 248.0), 'Lung Opacity': (0.1881131938533695, 503.0), 'No Finding': (0.9849398212298939, 2099.0), 'Nodule/Mass': (0.04727705078676374, 502.0), 'Other lesion': (0.018439570279852546, 393.0), 'Pleural effusion': (0.20265801851048199, 461.0), 'Pleural thickening': (0.08399339496799231, 918.0), 'Pneumothorax': (0.09913461538461539, 26.0), 'Pulmonary fibrosis': (0.10960661234685283, 886.0)}\n",
      "|EPOCH 15| TRAIN_LOSS 0.6100621295137155| VALID_LOSS 0.5772378597930073|\n",
      "Best model found for Fold 0 in Epoch 15........Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1031/1031 [27:23<00:00,  1.59s/it, loss=0.576]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|EPOCH 16| TRAIN_LOSS 0.575671928265393| VALID_LOSS 0.5772378597930073|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    model_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-negative",
   "metadata": {
    "papermill": {
     "duration": 27.92095,
     "end_time": "2021-05-24T17:19:16.556264",
     "exception": false,
     "start_time": "2021-05-24T17:18:48.635314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-material",
   "metadata": {
    "papermill": {
     "duration": 27.613451,
     "end_time": "2021-05-24T17:20:11.359779",
     "exception": false,
     "start_time": "2021-05-24T17:19:43.746328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8.1 Load model\n",
    "\n",
    "After training the model, comment the line \"model = run(fold=0)\", and load the model to run the predictions in the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faced-nickname",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:21:06.815163Z",
     "iopub.status.busy": "2021-05-24T17:21:06.812928Z",
     "iopub.status.idle": "2021-05-24T17:21:06.815943Z",
     "shell.execute_reply": "2021-05-24T17:21:06.816488Z"
    },
    "papermill": {
     "duration": 28.032845,
     "end_time": "2021-05-24T17:21:06.816648",
     "exception": false,
     "start_time": "2021-05-24T17:20:38.783803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    ## Loading a model\n",
    "    num_classes = 15\n",
    "    num_queries = 2\n",
    "    model = DETRModel(num_classes=num_classes,num_queries=num_queries)\n",
    "    model.load_state_dict(torch.load(\"../input/detr-model/detr_model.pth\", map_location=torch.device('cpu')))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-emergency",
   "metadata": {
    "papermill": {
     "duration": 27.779625,
     "end_time": "2021-05-24T17:22:01.839111",
     "exception": false,
     "start_time": "2021-05-24T17:21:34.059486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8.2 Plotting results\n",
    "Plotting expected and predicted boxes with labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "consistent-advisory",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:22:56.991699Z",
     "iopub.status.busy": "2021-05-24T17:22:56.989371Z",
     "iopub.status.idle": "2021-05-24T17:22:56.992557Z",
     "shell.execute_reply": "2021-05-24T17:22:56.993115Z"
    },
    "papermill": {
     "duration": 27.405789,
     "end_time": "2021-05-24T17:22:56.993278",
     "exception": false,
     "start_time": "2021-05-24T17:22:29.587489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# COCO classes\n",
    "CLASSES = [\n",
    "    'Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Consolidation',\n",
    "    'ILD', 'Infiltration', 'Lung Opacity', 'Nodule/Mass', 'Other lesion', \n",
    "    'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'No Finding'\n",
    "]\n",
    "\n",
    "# colors for visualization\n",
    "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "european-morning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:23:52.455075Z",
     "iopub.status.busy": "2021-05-24T17:23:52.454254Z",
     "iopub.status.idle": "2021-05-24T17:23:52.458608Z",
     "shell.execute_reply": "2021-05-24T17:23:52.457993Z"
    },
    "papermill": {
     "duration": 27.903821,
     "end_time": "2021-05-24T17:23:52.458754",
     "exception": false,
     "start_time": "2021-05-24T17:23:24.554933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unusual-liquid",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:24:48.099469Z",
     "iopub.status.busy": "2021-05-24T17:24:48.088963Z",
     "iopub.status.idle": "2021-05-24T17:24:48.118852Z",
     "shell.execute_reply": "2021-05-24T17:24:48.119461Z"
    },
    "papermill": {
     "duration": 27.827124,
     "end_time": "2021-05-24T17:24:48.119636",
     "exception": false,
     "start_time": "2021-05-24T17:24:20.292512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def view_sample_check_MAP(df_valid,model,device, index_to_show):\n",
    "    map_df = pd.DataFrame()\n",
    "    map_df_target = pd.DataFrame()    \n",
    "    \n",
    "    valid_dataset = VinDataset(\n",
    "    image_ids=df_valid.index.values,\n",
    "    dataframe=df_valid,\n",
    "    transforms=get_valid_transforms()\n",
    "    )\n",
    "    \n",
    "    valid_data_loader = DataLoader(valid_dataset,\n",
    "                                   batch_size=164,\n",
    "                                   shuffle=False,\n",
    "                                   num_workers=4,\n",
    "                                   collate_fn=collate_fn)\n",
    "    \n",
    "    images, targets, image_ids = next(iter(valid_data_loader))\n",
    "    #print(\"targets[index_to_show] : {}\".format(targets[index_to_show]))\n",
    "    _,h,w = images[index_to_show].shape # for de normalizing images\n",
    "    print(\"h,w  : {}\".format(h,w))\n",
    "    print(\"targets[index_to_show]['labels']  : {}\".format(targets[index_to_show]['labels']))\n",
    "    images = list(img.to(device) for img in images)\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    annotated_boxes = targets[index_to_show]['boxes'].cpu().numpy()\n",
    "    print(\"Anottated boxes.shape AFTER picking \"\"index_to_show .shape\"\"  : {}\".format(annotated_boxes.shape))\n",
    "    print(\"Anottated boxes[0] AFTER picking \"\"index_to_show\"\"  : {}\".format(annotated_boxes[0]))\n",
    "    annotated_boxes = [np.array(box).astype(np.int32) for box in A.augmentations.bbox_utils.denormalize_bboxes(annotated_boxes,h,w)]\n",
    "    print(\"denormalize_bboxes Anottated boxes[0] AFTER picking \"\"index_to_show\"\" (in coco) : {}\".format(annotated_boxes[0]))    \n",
    "    #annotated_boxes = rescale_bboxes(annotated_boxes[index_to_show], (512,512))         \n",
    "    \n",
    "    # MAP targets\n",
    "    for count, label in enumerate(targets[index_to_show]['labels']):\n",
    "        print(\"label : {}\".format(label))\n",
    "        text = f'{CLASSES[label]}' \n",
    "        print(\"text : {}\".format(text))\n",
    "        xmin = targets[index_to_show]['boxes'][count][0] - (targets[index_to_show]['boxes'][count][2])/2\n",
    "        xmax = targets[index_to_show]['boxes'][count][0] + (targets[index_to_show]['boxes'][count][2])/2  \n",
    "        ymin = targets[index_to_show]['boxes'][count][1] - (targets[index_to_show]['boxes'][count][3])/2\n",
    "        ymax = targets[index_to_show]['boxes'][count][1] + (targets[index_to_show]['boxes'][count][3])/2\n",
    "\n",
    "        data = pd.DataFrame({\"ImageID\": [image_ids[0]],\"LabelName\": [text],\n",
    "        \"XMin\": [xmin.item()], \"XMax\": [xmax.item()], \"YMin\": [ymin.item()], \"YMax\": [ymax.item()]})\n",
    "        map_df_target = map_df_target.append(data)     \n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    cpu_device = torch.device(\"cpu\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)   \n",
    "\n",
    "    # keep only predictions with 0.7+ confidence\n",
    "    print(\"outputs['pred_logits'].shape : {}\".format(outputs['pred_logits'].shape))\n",
    "    print(\"outputs['pred_logits'].softmax(-1).shape : {}\".format(outputs['pred_logits'].softmax(-1).shape))\n",
    "    print(\"outputs['pred_logits'].softmax(-1)[0, :, :-1].shape : {}\".format(outputs['pred_logits'].softmax(-1)[0, :, :-1].shape))\n",
    "    probas = outputs['pred_logits'].softmax(-1)[index_to_show, :, :-1]\n",
    "    print(\"probas.shape : {}\".format(probas.shape))\n",
    "    keep = probas.max(-1).values > 0.08\n",
    "    print(\"keep : {}\".format(keep))\n",
    "    # convert boxes from [0; 1] to image scales\n",
    "    \n",
    "    print(\"outputs['pred_boxes'].shape : {}\".format(outputs['pred_boxes'].shape))\n",
    "    #print(\"outputs['pred_boxes'][index_to_show]: {}\".format(outputs['pred_boxes'][index_to_show]))\n",
    "    \n",
    "    boxes = rescale_bboxes(outputs['pred_boxes'][index_to_show, keep], (512,512))\n",
    "    print(\"Predicted boxes.shape AFTER picking \"\"index_to_show\"\"  : {}\".format(boxes.shape))\n",
    "    #print(\"Predicted boxes[0] AFTER picking \"\"index_to_show\"\" (in pascal) : {}\".format(boxes[0]))\n",
    "    prob = probas[keep]\n",
    "    #return probas[keep],bboxes_scaled,image_ids\n",
    "\n",
    "    string_from_image = f\"../input/vinbigdata-512-image-dataset/vinbigdata/train/{image_ids[index_to_show]}.png\"\n",
    "    \n",
    "    im = Image.open(string_from_image)\n",
    "    pil_img = im.convert('RGB')\n",
    "    pil_img.save('colors.jpg')\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    #print(\"prob : {}\".format(prob))\n",
    "    for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   fill=False, color=c, linewidth=3))\n",
    "        print(\"xmin : {}\".format(xmin))\n",
    "        print(\"ymin : {}\".format(ymin))\n",
    "        print(\"xmax : {}\".format(xmax))\n",
    "        print(\"ymax : {}\".format(ymax))\n",
    "        \n",
    "        cl = p.argmax()\n",
    "        print(\"cl : {}\".format(cl))\n",
    "        text = f'{CLASSES[cl]}: {p[cl]:0.2f}'\n",
    "        text_df = f'{CLASSES[cl]}'\n",
    "        \n",
    "        # Dataframe for MAP\n",
    "        data = pd.DataFrame({\"ImageID\": [image_ids[0]],\"LabelName\": [text_df], \"Conf\": [p[cl].item()], \"XMin\": [xmin/512], \"XMax\": [xmax/512], \"YMin\": [ymin/512], \"YMax\": [ymax/512]})\n",
    "        map_df = map_df.append(data)\n",
    "        ax.text(xmin, ymin, text, fontsize=15,\n",
    "                bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the onces annotated by the doctors\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    #print(\"prob : {}\".format(prob))\n",
    "    for p, (x0, x1, x2, x3), c in zip(targets[index_to_show]['labels'], annotated_boxes, colors):\n",
    "        ax.add_patch(plt.Rectangle((x0-x2/2, x1-x3/2), x2, x3,\n",
    "                                   fill=False, color=c, linewidth=3))\n",
    "        #print(\"x0 : {}\".format(x0))\n",
    "        #print(\"x1 : {}\".format(x1))\n",
    "        #print(\"x2 : {}\".format(x2))\n",
    "        #print(\"x3 : {}\".format(x3))\n",
    "        #print(\"annotated_boxes : {}\".format(annotated_boxes))\n",
    "        cl = p\n",
    "        print(\"cl : {}\".format(cl))\n",
    "        text = f'{CLASSES[cl]}'\n",
    "        ax.text(x0, x1, text, fontsize=15,\n",
    "                bbox=dict(facecolor='yellow', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"map_df_target : {}\".format(map_df_target))\n",
    "    print(\"map_df : {}\".format(map_df))\n",
    "    \n",
    "    ann = map_df_target[['ImageID', 'LabelName', 'XMin', 'XMax', 'YMin', 'YMax']].values\n",
    "    det = map_df[['ImageID', 'LabelName', 'Conf', 'XMin', 'XMax', 'YMin', 'YMax']].values\n",
    "    mean_ap, average_precisions = mean_average_precision_for_boxes(ann, det)\n",
    "\n",
    "    print(\"mean_ap : {}\".format(mean_ap))\n",
    "    print(\"average_precisions : {}\".format(average_precisions))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "unexpected-revision",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:25:43.664855Z",
     "iopub.status.busy": "2021-05-24T17:25:43.663845Z",
     "iopub.status.idle": "2021-05-24T17:25:43.667472Z",
     "shell.execute_reply": "2021-05-24T17:25:43.666889Z"
    },
    "papermill": {
     "duration": 27.918144,
     "end_time": "2021-05-24T17:25:43.667612",
     "exception": false,
     "start_time": "2021-05-24T17:25:15.749468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_results():\n",
    "    train_df = preprocessing()\n",
    "    model = load_model()\n",
    "    view_sample_check_MAP(train_df[train_df['kfold'] == 0],model=model,device=torch.device('cpu'),index_to_show=10)\n",
    "    return\n",
    "# uncomment if you want to visualize the training results \n",
    "#visualize_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-wrestling",
   "metadata": {
    "papermill": {
     "duration": 27.458131,
     "end_time": "2021-05-24T17:26:38.268148",
     "exception": false,
     "start_time": "2021-05-24T17:26:10.810017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 8.3 Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bizarre-catering",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:27:33.055815Z",
     "iopub.status.busy": "2021-05-24T17:27:33.054694Z",
     "iopub.status.idle": "2021-05-24T17:27:33.058152Z",
     "shell.execute_reply": "2021-05-24T17:27:33.057573Z"
    },
    "papermill": {
     "duration": 27.661642,
     "end_time": "2021-05-24T17:27:33.058324",
     "exception": false,
     "start_time": "2021-05-24T17:27:05.396682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DIR_TEST = f'../input/vinbigdata-512-image-dataset/vinbigdata/test'\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "class VinDataset_for_test(Dataset):\n",
    "    def __init__(self,image_ids,dataframe,transforms=None):\n",
    "        self.image_ids = image_ids\n",
    "        self.df = dataframe\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        image_id = self.image_ids[index]\n",
    "        records = self.df.loc[image_id]\n",
    "        labels = records['class_id']\n",
    "        image = cv2.imread(f'{DIR_TEST}/{image_id}.png', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    " \n",
    "        # DETR takes in data in coco format    \n",
    "        boxes = records[['coco_x', 'coco_y', 'coco_w', 'coco_h']].values\n",
    "\n",
    "        #print(\"boxes : {}\".format(boxes))\n",
    "     \n",
    "        # AS pointed out by PRVI It works better if the main class is labelled as zero\n",
    "        labels =  np.array(labels)\n",
    "    \n",
    "        if boxes.ndim == 1 : \n",
    "            boxes = np.expand_dims(boxes, axis=0)\n",
    "            labels = np.expand_dims(labels, axis=0)\n",
    "        \n",
    "        # AS pointed out by PRVI It works better if the main class is labelled as zero\n",
    "        labels =  np.array(labels)\n",
    "        \n",
    "        if self.transforms:\n",
    "            sample = {\n",
    "                'image': image,\n",
    "                'bboxes': boxes,\n",
    "                'labels': labels\n",
    "            }      \n",
    "        \n",
    "        sample = self.transforms(**sample)\n",
    "        image = sample['image']\n",
    "        boxes = sample['bboxes']\n",
    "        labels = sample['labels']\n",
    "   \n",
    "        # Normalizing BBOXES\n",
    "        _,h,w = image.shape\n",
    "        boxes = A.augmentations.bbox_utils.normalize_bboxes(sample['bboxes'],rows=h,cols=w)\n",
    "        #print(\"boxes after normalization : {}\".format(boxes))  \n",
    "        target = {}\n",
    "        target['boxes'] = torch.as_tensor(boxes,dtype=torch.float32)\n",
    "        target['labels'] = torch.as_tensor(labels,dtype=torch.long)\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "        #print(\"image_id : {}\".format(image_id))\n",
    "        \n",
    "        return image/255, target, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "recorded-manual",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:28:28.951648Z",
     "iopub.status.busy": "2021-05-24T17:28:28.950327Z",
     "iopub.status.idle": "2021-05-24T17:28:28.955735Z",
     "shell.execute_reply": "2021-05-24T17:28:28.955149Z"
    },
    "papermill": {
     "duration": 27.799975,
     "end_time": "2021-05-24T17:28:28.955870",
     "exception": false,
     "start_time": "2021-05-24T17:28:01.155895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_xray(path, voi_lut = True, fix_monochrome = True):\n",
    "    dicom = pydicom.read_file(path)\n",
    "\n",
    "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "\n",
    "    # depending on this value, X-ray may look inverted - fix that:\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "\n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    data = np.stack([data]*3).transpose(1,2,0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "optical-julian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:29:24.554798Z",
     "iopub.status.busy": "2021-05-24T17:29:24.545259Z",
     "iopub.status.idle": "2021-05-24T17:29:24.558229Z",
     "shell.execute_reply": "2021-05-24T17:29:24.557640Z"
    },
    "papermill": {
     "duration": 28.269173,
     "end_time": "2021-05-24T17:29:24.558372",
     "exception": false,
     "start_time": "2021-05-24T17:28:56.289199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predictions(model):\n",
    "    DIR_INPUT = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection'\n",
    "    test_df = pd.read_csv(f'{DIR_INPUT}/sample_submission.csv')\n",
    "    test_df['coco_x']=[1 for i in range(3000)]\n",
    "    test_df['coco_y']=[1 for i in range(3000)]\n",
    "    test_df['coco_w']=[1 for i in range(3000)]\n",
    "    test_df['coco_h']=[1 for i in range(3000)]\n",
    "    test_df['class_id']=[1 for i in range(3000)]\n",
    "    test_df['kflod']=[88 for i in range(3000)]\n",
    "    test_df['class_confidence_box'] = [[] for i in range(3000)]\n",
    "    test_df.set_index('image_id', inplace=True)\n",
    "    valid_dataset = VinDataset_for_test(image_ids=test_df.index.values,\n",
    "                                        dataframe=test_df,\n",
    "                                        transforms=get_valid_transforms()\n",
    "                                        )\n",
    "\n",
    "    valid_data_loader = DataLoader(valid_dataset,\n",
    "                                   batch_size=1,\n",
    "                                   shuffle=False,\n",
    "                                   num_workers=4,\n",
    "                                   collate_fn=collate_fn)\n",
    "\n",
    "    dataloader_iterator = iter(valid_data_loader)\n",
    "\n",
    "    for i in range(test_df.shape[0]):\n",
    "        images, targets, image_ids = next(dataloader_iterator)\n",
    "        _,h,w = images[0].shape # for de normalizing images\n",
    "       \n",
    "        #print(\"image_ids[0] : {}\".format(image_ids[0]))\n",
    "        device=torch.device('cpu')\n",
    "        images = list(img.to(device) for img in images)\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "        cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images) \n",
    "        #print(\"outputs : {}\".format(outputs))\n",
    "        # keep only predictions with 0.7+ confidence\n",
    "        #print(\"outputs['pred_logits'].shape : {}\".format(outputs['pred_logits'].shape))\n",
    "        #print(\"outputs['pred_logits'].softmax(-1) : {}\".format(outputs['pred_logits'].softmax(-1)))\n",
    "        #print(\"outputs['pred_logits'].softmax(-1)[0, :, :-1].shape : {}\".format(outputs['pred_logits'].softmax(-1)[0, :, :-1].shape))\n",
    "        probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
    "        keep = probas.max(-1).values > 0.08\n",
    "        #print(\"keep : {}\".format(keep))\n",
    "        # convert boxes from [0; 1] to image scales\n",
    "\n",
    "        #print(\"outputs['pred_boxes'].shape : {}\".format(outputs['pred_boxes'].shape))\n",
    "\n",
    "        boxes = rescale_bboxes(outputs['pred_boxes'][0, keep], (512,512))\n",
    "        ####print(\"boxes : {}\".format(boxes))\n",
    "        #print(\"Predicted boxes.shape AFTER picking \"\"0\"\"  : {}\".format(boxes.shape))\n",
    "        #print(\"Predicted boxes shape (in pascal) : {}\".format(boxes.shape))\n",
    "        #print(\"Predicted boxes[0] \"\"0\"\" (in pascal) : {}\".format(boxes[0]))\n",
    "        prob = probas[keep]\n",
    "        for i in range(prob.shape[0]) :\n",
    "            class_pred = prob[i].argmax()\n",
    "            #print(\"prob[i].max() : {}\".format(prob[i].max()))\n",
    "            #print(\"class_pred : {}\".format(class_pred))\n",
    "\n",
    "        # Read the dicom with id \"image_ids[0]\" to get the actual size\n",
    "        image_dicom = read_xray(f'../input/vinbigdata-chest-xray-abnormalities-detection/test/{image_ids[0]}.dicom')\n",
    "        dicom_y = image_dicom.shape[0]\n",
    "        dicom_x = image_dicom.shape[1]\n",
    "        ####print(\"image_dicom.shape : {}\".format(image_dicom.shape))        \n",
    "        ####print(\"dicom_x : {}\".format(dicom_x))   \n",
    "        ####print(\"dicom_y : {}\".format(dicom_y))   \n",
    "\n",
    "        #print(\"prob : {}\".format(prob))\n",
    "        for i in range(prob.shape[0]) :\n",
    "            class_pred = prob[i].argmax()\n",
    "            box_list = boxes[i].tolist()\n",
    "            ####print(\"box_list : {}\".format(box_list))\n",
    "\n",
    "            # Rescale the box based on the actual size\n",
    "            box_list[0] = (dicom_x/512) *  box_list[0]\n",
    "            box_list[2] = (dicom_x/512) *  box_list[2]\n",
    "\n",
    "            box_list[1] = (dicom_y/512) *  box_list[1]\n",
    "            box_list[3] = (dicom_y/512) *  box_list[3]\n",
    "            if class_pred != 14:\n",
    "                boxz_string= ' '.join(str(e) for e in box_list)\n",
    "                test_df.loc[image_ids]['class_confidence_box'].append([str(class_pred.numpy()), str(prob[i].max().numpy()),boxz_string])\n",
    "            else:\n",
    "                boxz_string= '0 0 1 1'\n",
    "                test_df.loc[image_ids]['class_confidence_box'].append([str(class_pred.numpy()), str(prob[i].max().numpy()),boxz_string])\n",
    "\n",
    "        list_of_results = test_df.loc[image_ids]['class_confidence_box']\n",
    "        list_of_results = [' '.join(im) for im in list_of_results]\n",
    "    #    print(\"list_of_results : {}\".format(list_of_results))    \n",
    "\n",
    "        #Assign the final string to \"PredictionString\"\n",
    "        if not list_of_results:\n",
    "            pass\n",
    "        else:\n",
    "            test_df.loc[image_ids,'PredictionString'] =' '.join(list_of_results)\n",
    "\n",
    "    #print(\"test_df.loc[image_ids]['class_confidence_box'] : {}\".format(test_df.loc[image_ids]['class_confidence_box']))\n",
    "    test_df.drop(['coco_x', 'coco_y','coco_w', 'coco_h','class_id', 'kflod', 'class_confidence_box'], axis=1, inplace=True)\n",
    "    test_df['image_id'] = test_df.index\n",
    "    test_df = test_df[['image_id','PredictionString']]\n",
    "    test_df.to_csv('submission.csv', index=False)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "composite-sherman",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:30:20.123804Z",
     "iopub.status.busy": "2021-05-24T17:30:20.122666Z",
     "iopub.status.idle": "2021-05-24T17:30:20.126008Z",
     "shell.execute_reply": "2021-05-24T17:30:20.125474Z"
    },
    "papermill": {
     "duration": 27.744888,
     "end_time": "2021-05-24T17:30:20.126181",
     "exception": false,
     "start_time": "2021-05-24T17:29:52.381293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction_model():\n",
    "    print(\"to load model\")\n",
    "    model = load_model()\n",
    "    print(\"model loaded\")\n",
    "    predictions(model)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "gothic-plaintiff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T17:31:16.420730Z",
     "iopub.status.busy": "2021-05-24T17:31:16.419706Z",
     "iopub.status.idle": "2021-05-24T17:31:16.423226Z",
     "shell.execute_reply": "2021-05-24T17:31:16.422654Z"
    },
    "papermill": {
     "duration": 27.797827,
     "end_time": "2021-05-24T17:31:16.423362",
     "exception": false,
     "start_time": "2021-05-24T17:30:48.625535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if mode == 'predict':\n",
    "    prediction_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-pittsburgh",
   "metadata": {
    "papermill": {
     "duration": 26.75933,
     "end_time": "2021-05-24T17:32:11.097670",
     "exception": false,
     "start_time": "2021-05-24T17:31:44.338340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31233.578954,
   "end_time": "2021-05-24T17:32:41.199948",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-24T08:52:07.620994",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "228bb1ec2aac4c66a677d0562cc3e22e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2525c1a7425647519937e613d2e5d314": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dd5ab529e38a41b9b84d6dd17bcb2093",
        "IPY_MODEL_70c23b50ac324941a97c5abfb380e87a",
        "IPY_MODEL_2a575948f9374fc0a0e0bc30d5eb2929"
       ],
       "layout": "IPY_MODEL_733b6357afd948f69b176869d636deaa"
      }
     },
     "2a575948f9374fc0a0e0bc30d5eb2929": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ff006d133d0741b48cc02d8b83e92715",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d45448e9e2a64a8d9d93f71bb0b0af6d",
       "value": " 159M/159M [00:14&lt;00:00, 12.2MB/s]"
      }
     },
     "4d305a55fdb748c8b8ece45af968a76e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4e511546abcb4b079cfd7ca1811cc513": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "565a1eb8215a46ec842e0d9605581364": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_636bf3e9261f4d7384cc544b26d4d015",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_4e511546abcb4b079cfd7ca1811cc513",
       "value": "100%"
      }
     },
     "5955e7fb983c48188d62a51ce4cfb44e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "636bf3e9261f4d7384cc544b26d4d015": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70c23b50ac324941a97c5abfb380e87a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_db6d48ad81304787b2ee9f75706887a6",
       "max": 166618694.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5955e7fb983c48188d62a51ce4cfb44e",
       "value": 166618694.0
      }
     },
     "733b6357afd948f69b176869d636deaa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9aeee9fc87774659856c3d2add1df79c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "adedf316de9346fe9c2b191eae64e748": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b77c12d4639c49c2b8e09ee81c198e25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_adedf316de9346fe9c2b191eae64e748",
       "max": 102502400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4d305a55fdb748c8b8ece45af968a76e",
       "value": 102502400.0
      }
     },
     "bbf40ca4661d4457a0dc21cd936f2148": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bcd25b4a12da4161ac22e4b0d451c6c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d45448e9e2a64a8d9d93f71bb0b0af6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d6bdc91ad789450f94c552ed188e1b40": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db6d48ad81304787b2ee9f75706887a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dbf666970a7e42fb9a9c43196e6f2673": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_565a1eb8215a46ec842e0d9605581364",
        "IPY_MODEL_b77c12d4639c49c2b8e09ee81c198e25",
        "IPY_MODEL_f7cccafa2fa54cde8fc9c681136e032c"
       ],
       "layout": "IPY_MODEL_d6bdc91ad789450f94c552ed188e1b40"
      }
     },
     "dd5ab529e38a41b9b84d6dd17bcb2093": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bcd25b4a12da4161ac22e4b0d451c6c2",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_bbf40ca4661d4457a0dc21cd936f2148",
       "value": "100%"
      }
     },
     "f7cccafa2fa54cde8fc9c681136e032c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_228bb1ec2aac4c66a677d0562cc3e22e",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_9aeee9fc87774659856c3d2add1df79c",
       "value": " 97.8M/97.8M [00:01&lt;00:00, 54.5MB/s]"
      }
     },
     "ff006d133d0741b48cc02d8b83e92715": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
